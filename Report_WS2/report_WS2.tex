% Report
\documentclass{article}

% Here set the various packages
\input{Style/packages}
%%%

\title{Programming of Supercomputers\\Worksheet 2}
\author{
	\begin{tabular}{rl}
		Oleksandr Voloshyn& \texttt{<o.voloshyn@tum.de>}\\ 
		Qunsheng Huang& \texttt{<keefe.huang@tum.de>}\\ 
		Tommaso Bianucci& \texttt{<bianucci@in.tum.de>}
	\end{tabular}
}
\date{\today}

\begin{document}

\maketitle
\renewcommand{\abstractname}{Group members's contributions}
\begin{abstract}
	\begin{center}
		\begin{tabular}{rl}
		% Here write the contributions of the members of the group
		Oleksandr Voloshyn:& worked on Task 2 to 5. \\
		Qunsheng Huang:& worked on Task 2 to 5.\\
		Tommaso Bianucci:& worked on Task 1 and Task 6.\\
		\end{tabular}
	\end{center}
\end{abstract}

\section{Task 1: Understanding Parallel Programming Challenges}
\subsection{Concepts description}
\begin{description}
	\item[Race condition]

	It is a concurrent access to data by two different threads in which the outcome of the program changes depending on the order of the accesses. This leads to non-deterministic behaviour of the program.

	\item[Deadlock]

	A condition in which two or more threads are waiting on each other before continuing execution, therefore blocking each other execution indefinitely.
	
	\item[Heisenbug] 

	A bug which occurrence is influenced by the use of a debugging technique or tool, as e.g. the presence of a debugger. The debugging technique prevents the bug from occurring or alters its behaviour, making it more difficult to locate and adress the problem.
	
	\item[Cache coherency and false sharing] 

	\emph{Cache coherency} refers to the coherency that shared data must have when loaded into multiple local processor caches. Cache coherency is typically enforced by hardware mechanisms propagating the changes across caches, ensuring that multiple processors working on the same data do not end up working on different and incoherent versions of it.

	\emph{False sharing} is an unwanted side effect of cache coherency mechanisms and of the fact that caches do not store data in an individual fashion but in blocks, called cache lines. False sharing occurs when two processors load the same cache line but work on different data within this cache line. Each write operation from one processor will cause the other one to have to reload this cache line, even if the change was in data which will not be used by the other processor.
	
	\item[Load imbalance] 

	A load imbalance is a situation in which two processors are given different amount of work to perform concurrently. This is usually a cause of performance degradation, as the less loaded processor will have to idle while waiting for the more loaded one to finish.
	
	\item[Amdahl's law] 

	If a program has a fraction $f$ which is parallelizable and and the remaining $(1-f)$ which is inherently sequential, we can estimate the time it takes to execute it on $N$ processors as:
	\begin{align}
		T(N) =& f \cdot \frac{T(1)}{N} + (1 - f) \cdot T(1)\\
		=& T(1) \cdot (1 - f + \frac{f}{N})
	\end{align}
	Therefore $lim_{N\to\infty} T(N) = T(1) \cdot (1 - f)$. So we can see that performance improvement is asymptotically limited by the non-parallelizable fraction of the program.

	\item[Parallelization overhead] This is the additional performance cost caused by managing the parallelization, as e.g. the additional time spent in communication, synchronization or creating, destroying and scheduling threads.
	
	\item[Floating-point arithmetic challenges] ~
		\begin{description}
			\item[Comparisons] Comparing floating point numbers can be challanging because due to finite precision representation, errors and rounding it is always possible to get results which are slightly different than the expected ones.
			Also, finite precision representation does not allow for all real values to be represented and it even fails to represent all integers from a certain threshold onwards\footnote{If $mb$ is the number of bits the mantissa consists of, then $1+2^{mb + 1}$ is the first non representable integer.}.

			Checking \verb!a == b! is therefore dangerous, while an acceptance range should be used, i.e. \verb!fabs(a-b) < tolerance!.
			\item[Definition of zero and signed zero] The IEEE 754 standard allows for both $+0$ and $-0$ representation: their exponent and mantissa is $0$ for both, but the sign bit can be 0 ($+$ case) or 1 ($-$ case).
			\item[Cancellation or loss of significance] Cancellation is an undesired side effect coming from performing subtractions in finite precision floating point arithmetics: if we subtract two values which are similar in magnitude, we obtain a result which is very small in magnitude but with increased relative error compared to the initial values, therefore losing significant digits in the process.
			\item[Amplification and error propagation] Any floating point value given as input to an algorithm is associated with a certain relative error or number of significant digits. The foating point operations which take place in the algorithm may amplify or reduce the relative error on these values, therefore causing the final result to potentially have a very different number of significant digits than the input values. Algorithms which amplify input relative errors are called \emph{unstable}, while those which reduce the relative errors are called \emph{stable}.
		\end{description}
\end{description}

\subsection{Questions}
\begin{enumerate}
	\item \hl{Which of the concepts affect performance but not correctness?}

	False sharing, load imbalance, Amdahl's law and parallelization overhead.

	\item \hl{Which of the concepts affect the correctness of the application?}

	Deadlocks, race conditions, heisenbugs and the floating-point arithmetic challenges.

	Cache coherency is usually an hardware-provided feature: assuming it is correctly implemented it should be just considered as a performance problem. However if the programmer must in some way ensure cache coherency, then there is a risk for correctness issues.

	\begin{enumerate}[label=\Alph*]
		\item \hl{Of these, which are exclusive to parallel programming?}

		Deadlocks and race conditions.

		\item \hl{Of these, which are not exclusive to parallel programming?}

		Heisenbugs and floating-point arithmetic challenges.

	\end{enumerate}

	\item \hl{Which of them can occur in OpenMP applications?}

	All of them.
	
	\item \hl{Which of them can occur in MPI applications?}

	All of them, except for false sharing and cache coherency.
	
	\item \hl{Is cache coherency necessary on MPI applications with a single process and a single thread per rank? Explain.}

	No, if there is no degree of shared memory parallelization there is no need to ensure coherency, as just one thread can touch its memory region.
	
	\item \hl{Is Amdahl's law applicable to strong scaling applications? Explain.}

	Yes, it is precisely designed to model and explain the challanges of strong scaling as it assumes a fixed problem size and an increase in the number of processors.
	
	\item \hl{Is Amdahl's law applicable to weak scaling applications? Explain.}

	No, as explained in the previous answer, Amdahl's law assumes a fixed fraction of the application cost is parallelizable. However by changing the problem size, the parallelizable and inherently sequential fractions may change.

	A law addressing weak scaling is \emph{Gustafson's law}.
	
	\item \hl{Which of these limit the scalability of applications?}

	Amdahl's law, parallelization overheads, load imbalance and false sharing.
	
\end{enumerate}

% % Figure example
% \begin{figure}[h!] % h=here, t=top, b=bottom, p=(extra)page, !=force
%  	\begin{center}
%  		\includegraphics[width=.9\linewidth]{figure.png} % It searches in the Figures/ folder!
%  		\caption{Caption text}
%  		\label{fig:figureLabelName}
%  	\end{center}
% \end{figure}

\section{Task 2: TotalView GUI}

	\begin{enumerate}
	

	\item \hl{Include a brief description of the following aspects of TotalViews GUI in the report:}
	\end{enumerate}
	\begin{itemize}
	\item \hl{Session Manager}
	
	Manages debugging sessions, see Fig.\ref{fig:sess_manager}. 
	Displays previously configured debugging systems---allowing editing, copying and deleting of preivous settings, and view their respective configuration setups. 
	Available configurations include type of session (parallel/sequential), parallel implementation (poe-linux/MPICH etc.), number of parallel processes, number of nodes, environmental variables and input to parallel program upon startup.
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}	
		\includegraphics[width=.7\linewidth]{SessionManager.png}
		\caption{Session manager}
		\label{fig:sess_manager}
		\end{center}
	\end{figure}
	\item \hl{Root Window}
	
	Lists all processes and threads controlled by TotalView, see \ref{fig:root_window}. 
	Allows user to "Dive" into processes easily, which launches a process window for the selected process.
	Allows grouping of threads/processes for easier debugging.
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
	\begin{center}
			\includegraphics[width=.7\linewidth]{RootWindow.png}
		\caption{Root Window}
		\label{fig:root_window}
	\end{center}
	\end{figure}
	\item \hl{Process Window}
	
	Window for one specific process or thread, see Fig. \ref{fig:proc_window}. 
	Provides information on state of the process and its individual threads. 
	Information provided listed in the various panes below.
	\begin{itemize}
		\item \hl{Stack Trace Pane}
		
		Displays the call stack with any active threads, ie lists the active subroutines of the active thread. 
		Able to move up and down the call stack by clicking on the stack frame (routine name) of interest.
		Stack Frame pane and Source pane updated for the specific routine when it is selected. 
		Local variables are also available in the Local Variables (VAR) Panel.
		\item \hl{Stack Frame Pane}
		
		Displays information on the current thread's variables, ie allows users to see the current/stored values in existing variables. 
		The frame is seen in Fig \ref{fig:diving}.
		\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.7\linewidth]{SourceFrame.png}
		\caption{Diving in Function}
		\label{fig:diving}
		\end{center}
	\end{figure}
		\item \hl{Source Pane}
		
		Displays the source code for the main() function of the thread, process or selected routine
		\item \hl{Action Points, Processes, Threads Pane}
		\begin{itemize}
		\item The three tabs can be seen in Fig \ref{fig:action_proc_thread_tabs}.
		\item \hl{Process Tab} 
		
		The processes tab, or Ranks tab for MPI programs, contains a grid. 
		Each block in the grid represents one process. 
		The color of the respective segments indicates the state of the process. 
		\item \hl{Threads Tab} 
		
		The Threads Tab displays information about the state of your threads. 
		Clicking on a thread tells TotalView to shift the focus within the Process Window to that thread.
		\item \hl{Actions Points Tab} 
		
		Action points are specific actions performed when a particular source line is reached. 
		There are four possible actions: breakpoints, barrier points, eval points, and watch points.
		Totalview assigns unique ID numbers for each action point, these are seen in the actions points tab
		\end{itemize}
	\end{itemize}
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}	
		\includegraphics[width=.7\linewidth]{ActionTab.png}
		
		
		\includegraphics[width=.7\linewidth]{ProcessTab.png}
		
		
		\includegraphics[width=.7\linewidth]{ThreadTab.png}
		\caption{Action, Process \& Thread Tabs}
		\label{fig:action_proc_thread_tabs}
			\end{center}
	\end{figure}


	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.7\linewidth]{ProcessWindow.png}
		\caption{Process Window}
		\label{fig:proc_window}
		\end{center}
	\end{figure}

	\item \hl{Variable Window}
	
	Displays information about a program's objects. 
	Allows user to change the element values or to cast these values (changing how the value is displayed). 
	You can define fields which change how objects are viewed, for example: expression field (views result of a particular expression, ie. viewing a particular element in an array with expression 'val[3]' instead of 'val'.); type field (changing the data type of the particular element, and so on. 
	The user can also 'dive' into more complex elements to observe or change members of structures or elements of arrays. An example is seen in Fig \ref{fig:variable}.
	
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.7\linewidth]{VariableWindow.png}
		\caption{Variable Window}
		\label{fig:variable}
		\end{center}
	\end{figure}
	
\end{itemize}

\section{Task 3: Debugging with TotalView}
\begin{enumerate}
\item \hl{Describe in the report how the above operations are performed in TotalView}
	\begin{itemize}
	\item \hl{Control Execution}
	
	This controls how the user moves through the program. 
	There are a few options available: go, next, step, out, and run to. 
	Go executes the program normally and only stops with the addition of breakpoints. 
	Next runs the one line of code and advances to the next line. 
	Step runs until the next executable statement is reached. 
	Run to allows the user to run normally until a specific selected line. 
	Out is used to execute the return statement and exit a function. 
	All these options are available as clickable buttons along the top of the Process window, seen in Fig \ref{fig:stepping}.
		\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.4\linewidth]{ControlStepping.png}
		\caption{Control Execution}
		\label{fig:stepping}
		\end{center}
	\end{figure}
	\item \hl{Setting breakpoints}
	
	Breakpoints are the simplest form of Action Point availablein TotalView that stop the current threads execution when a specific line is reached. 
	They can be setup prior to running the process by clicking on the specific line number in the Source Pane or right clicking the line number and selecting "Set Breakpoint". 
	The line number will be highlighted and the new breakpoint will be visible in the Action Point tab.
	 Sample breakpoints can be seen in the Action Point tab in Fig \ref{fig:action_proc_thread_tabs}.
	\item \hl{Diving into functions}
	
	"Diving" is the term used by TotalView to focus on a function, process or variable. 
	To dive into a function, one can double-click on the function in the Processes tab or navigate to the function in the source view. 
	An example of diving into a function is seen in Fig \ref{fig:diving}, where we dive into function \verb!CalcFBHourglassForceForElems()!.
	
	\item \hl{View memory (variables and arrays)}
	
	Variables and arrays can be accesed in the Variables window. 
	This is accessed by double-clicking or right clicking and diving into specific variables in the Stack Frame menu. 
	An example is seen in Fig \ref{fig:variable}, where we view the values in array \verb!hourgam! in thread 24.

	\end{itemize}
\item \hl{Give a short explanation on why these operations are important in a debugger.}
	\begin{itemize}
	\item \hl{Control Execution}
	
	Control execution is important when debugging because it allow a systematic manner to execute segments of code. 
	For example, if one needs to pinpoint problematic segments of very large code, perhaps a normal "Run" command with certain breakpoints while observing key variables is a good starting point. 
	On the other hand, if one has a short problematic segment of code, repeatedly running Next to examine the effects of each line of code might be necessary to uncover more insidious bugs. 
	The available options allow for the user to move through code in an extremely flexible manner.
	\item \hl{Setting breakpoints}
		
	Breakpoints are extremely useful when debugging. 
	They cause the program to halt or stop execution at a specific interval for deeper analysis. 
	TotalView also allows for code execution during action points (known as eval points), which is extremely useful for evaluating behavior without having to specifically include calculation of variables of interest inside the examined code. 
	\item \hl{Diving into functions}
	
	Diving into functions allows for increased granularity when running code. 
	If one function is identified to be problematic, having the diving functionality allows the user to also control the execution inside the problematic function---allowing a more fine-grained view of the problematic function.	
	\item \hl{View memory (variables and arrays)}
	
	Most of the time, the side-effect of problematic code is incorrect variables or arrays, ie. data is incorrectly calculated. 
	Viewing specific variables or arrays allows the user to more clearly detect when unwanted behavior occurs. 
	This is especially the case when one is able to evaluate internal variables using code fragments (such as identifying the average of an array without explicitly calculating it in the code).

	\end{itemize}

\end{enumerate}

\section{Task 4: MPI with TotalView}
\begin{enumerate}
	\item \hl{State the name of the array you decided to visualize and include a snapshot of its visualization in the report.}
	
	It is not necessary to understand the actual meaning of the values in the array.
	The array we chose to visualise is the B \verb!Real_t! array in the \verb!CalcKinematicsForElems()!. 
	The snapshot of its visualisation can be seen in Fig \ref{fig:visual_array}.
	
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.7\linewidth]{VisualiseArray.png}
		\caption{Visualising Array}
		\label{fig:visual_array}
		\end{center}
	\end{figure}
	
	\item \hl{What is the name of the MPI rank variable in the benchmark?}
	
	The variable is \verb!myRank!
	\item \hl{What is the name of the MPI size variable in the benchmark?}
	
	The variable is \verb!numRanks!
	\item \hl{Where are these variables first set in the benchmarkâ€™s source code (file name and line number)?}
	
	When analysing the MPI function, we run on one node with 27 processes due to limited availability of nodes.
	We set breakpoints on lines 2708 and 2709. At breakpoint 2708, prior to the execution of \verb!MPI_Comm_size()!, we see that the variables \verb!numRanks! and \verb!myRank! are uninitialized and still contain trash values in Fig. \ref{fig:before_init}. 
	After \verb!MPI_Comm_size()! runs, we see that the values across the multiple processes all show 27 in Fig. \ref{fig:init_numranks}, which is the total number of threads. 
	The value of \verb!myRank! is still unchanged and is yet to be initialized. This then occurs when we look at the values of \verb!myRank! after \verb!MPI_Comm_rank()! is run, as seen in Fig. \ref{fig:init_myrank}. 
	\verb!numRanks! is set by \verb!MPI_Comm_size()! in lulesh.cc in line 2708 and \verb!myRank! is set by \verb!MPI_Comm_rank()! in lulesh.cc line 2709. 
	
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.7\linewidth]{StepBeforeInit.png}
		\caption{Before Initialising myRank and numRanks}
		\label{fig:before_init}
		\end{center}
	\end{figure}
	
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.7\linewidth]{numRankInit.png}
		\caption{Initialised numRanks}
		\label{fig:init_numranks}
		\end{center}
	\end{figure}
	
	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.7\linewidth]{myRankInit.png}
		\caption{Initialised myRank}
		\label{fig:init_myrank}
		\end{center}
	\end{figure}

\end{enumerate}

\section{Task 5: MPI+OpenMP with TotalView}
\begin{enumerate}
	\item \hl{Justify in the report the core and thread combination used.} ~

	We have decided to use 8 processes with 10 openMP threads for each. We need to
	use number of processes which is perfect cube. So the smallest number of processes bigger
	than 1 is 8. We decided to stick with this number because our total number of cores for 
	2 nodes is 80 and we can utilize all of them by using 10 openMP threads per process.
	This amount of openMP threads was close to optimal for openMP only benchmark done at the
	previous worksheet.
	
	Other options like 27 processes and 2 threads per process will allow us to use only half
	of the compute power available on the node. 64 processes restrict us to use 1 thread which
	means that our execution becomes MPI only and we can't observe any of the effects of hybrid
	program.

	\item \hl{Explain how threads and process counts are controlled in TotalView.} ~

	TotalView allows to see all the processes that were created by the session. All threads
	that are spawned by this processes are grouped according to their parrent. You can switch between
	different processes by clicking on the process tab at the bottom of the view or in the session
	window. \todo{ref}There you can also see current state of each process and thread.

	\item \hl{Explain what the fork-join model is.} ~

	Fork-join model is the model that is used by OpenMP. This model clearly specifies the master
	thread that is doing all of the sequential computations. At the point specified by programmer
	main thread distribute the work to all of the worker threads and becomes worker itself.
	At the end of the parallel region all of the threads wait at the implicit barier and 
	return control to master thread which continuing to work on sequential execution. 
	
	Overall program
	that use this model can be described as a sequence of parallel blocks and sequential regions
	between them. All of the sequential regions are done by master thread only, and parallel
	blocks are done by all(or part) of the available threads.

	\item \hl{Include a screen capture of the before and after effect of the fork-join model by navigatin to a parallel region and looking at the Threads Pane in TotalView.} ~
	
	Spawning threads is quite expencive task because it involves a lot of 
	communication with kernel. Before entering MPI init threads function we observe only one 
	main thread for each of the processes (Fig. \ref{fig:before_init_hybrid}).
	After call of the MPI init thread function we observe that each process creates internal threads
	for MPI (Fig. \ref{fig:after_init_hybrid}).
    After we reach first openMP pragma we can observe that 10 new threads were created by each of the 
	processes(Fig. \ref{fig:after_omp_region_hybrid}.
	However after implicit join at the end of the parallel block we see that all of the
	threads except of the master are in idle mode.
	
\end{enumerate}

\begin{figure}
    \begin{center}
        \includegraphics[width=.7\linewidth]{omp_before_init_squeeze_crop.png}
    \caption{Before MPI init threads}
    \label{fig:before_init_hybrid}
    \end{center}
\end{figure}
\begin{figure}
    \begin{center}
        \includegraphics[width=.7\linewidth]{omp_after_init_squeeze_crop.png}
    \caption{After MPI init threads}
    \label{fig:after_init_hybrid}
    \end{center}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=.7\linewidth]{omp_after_omp_squeeze_crop.png}
    \caption{After openMP parallel region}
    \label{fig:after_omp_region_hybrid}
    \end{center}
\end{figure}

\section{Task 6: MPI+OpenMP with Vampir}
\begin{enumerate}
	\item \hl{What are the main differences in the way events are recorded by gprof and Score-P?} ~

	Gprof perform \emph{profiling}, this means that the data it collects are aggregated by event type (e.g. the function called) and it provides a cumulative impact of each function over the entire application run. Profiling therefore discards any temporal information about the events.

	Score-P instead performs \emph{tracing}, meaning that each event detected is logged singularly together with its timestamp. This allows not only to understand the global impact each function has, but also to investigate the interplay of single events in time.

	It is worth also mentioning that both Gprof and Score-P support both sampling and instrumentation as techniques to obtain events data.

	\item \hl{Does Vampir support post-mortem or online analysis? Explain.} ~

	Post-mortem, as we need to first run the application with \verb!scorep! to collect the tracing data and, afterwards, we can analyze this data with Vampir. Therefore analysis can be performed only after the application ends.

	\item \hl{Explain the communication bottlenecks that occur in point-to-point and collective MPI communication. For example, late-sender, ...} ~

	Whether point-to-point or collective, blocking or non-blocking, in order for communication to take place processes need to coordinate and, ultimately, to synchronize at some point. If the working phase preceding the communication has different duration on the processes, e.g. because of load imbalance, then the communication can only be finalized when the slowest process has terminated its work and is able to communicate.

	\begin{description}
		\item[Point-to-point] In MPI P2P communication, an usual bottleneck is represented by the sender arriving at the communication point later than the receiver, making the receiver idle to wait for it. The reverse, i.e. the sender waiting for the receiver, 
		% is a rarer scenario, 
		is also possible but not necessarily leading to an idling sending process:
		in case of small enough messages, usually MPI implementations are able to internally buffer the message being sent and make the original send buffer available again to the user, making the \verb!MPI_Send()! call to return even if the corresponding \verb!MPI_Recv()! has not been posted yet.

		\item[Collectives] MPI collectives have to be executed by all processes belonging to the given communicator at the same time. Therefore all processes have to wait for the slowest one to reach the collective instruction.
	\end{description}

	Latencies can, to a certain degree, be hidden by using non-blocking communication schemes, i.e allowing processes to work on tasks which are independent of the communicated data while waiting for the communication to complete. However a consistent imbalance between the processes will ultimately cause idling also when using non-blocking communication.

	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.35\linewidth]{MPI_Allreduce_idling.png}
		\cprotect\caption{Idling caused by processes arriving at an \verb!MPI_Allreduce()! call at different times.}
		\label{fig:MPI_Allreduce_latency}
		\end{center}
	\end{figure}

	\item \hl{Take a screen capture of one of the MPI communication bottlenecks from the above question, and describe the situation.} ~

	The example chosen is that of a call to the \verb!MPI_Allreduce()! collective. Its effects are visible in Fig.\ref{fig:MPI_Allreduce_latency}: the different processes arrive at the \verb!MPI_Allreduce()! call at different times and ultimately they have to wait for process 0 to complete its work before all processes can resume.

	\item \hl{How does the Performance Radar help in analysis?} ~

	The Performance Radar allows defining a metric and getting the respective heatmap showing how the metric behaves across the different processes and threads over time. It is a quick way to locate specific problems based on the metric that describes them.
	An example related to the previous question is given by selecting the \emph{MPI Latencies} metric in the Performance Radar: with this we can quickly locate where MPI latencies originate and also immediately understand their severity.

	\item \hl{Describe the MPI message pattern in the Communication Matrix tab.} ~

	The Communication Matrix view highlights how each process communicates with any other process, in a fully interconnected way. However, if the metric used is \emph{Number of messages} or \emph{Aggregated message volume}, the Communication Matrix, shown in Fig.\ref{fig:commuMatrix}, appears to reveal the cube topology used for the MPI processes. Indeed the most used connection paths form a symmetric pattern---although not exactly symmetric in intensity---which suggests a \emph{neighbourhood} relationship.

	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.9\linewidth]{commuMatrix.png}
		\cprotect\caption{The \emph{hot} connections (in red and green) appear to reveal the topology used for MPI procesess (cube).}
		\label{fig:commuMatrix}
		\end{center}
	\end{figure}

	\item \hl{Take a screen capture of a fork-join, and describe the situation.} ~

	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.99\linewidth]{OMP_fork_join.png}
		\cprotect\caption{Timeline between OpenMP \emph{Fork} and \emph{Join} events on the various MPI processes.}
		\label{fig:ompForkJoin}
		\end{center}
	\end{figure}

	In Fig.\ref{fig:ompForkJoin} we can see a fork-join section of the benchmark execution. Before and after this block MPI communication takes place between the 8 \emph{master processes}---MPI communication arrows have been removed from the timeline for clarity. Within this block, additional join and forks take place for each master process: we have therefore a block with several OpenMP fork-join events between two MPI communication events.

	A closer inspection at one of these fork-join events reveals it comes from a parallelized for loop within the \verb!CalcAccelerationForNodes()! function.

	\item \hl{Do you observe any performance bottlenecks from Section 3.1 (Task 1) in the code?} ~

	Yes, the clearest to see is \emph{load imbalance}: its consequences appear either as a long \verb!MPI_Wait()!, uneven MPI collectives as \verb!MPI_Allreduce()! or \verb!omp implicit barrier! blocks in the timeline for some threads or processes while the slowest one is still working.

	\begin{figure}[p] % h=here, t=top, b=bottom, p=(extra)page, !=force
		\begin{center}
			\includegraphics[width=.9\linewidth]{functionSummary.png}
		\cprotect\caption{Function summary aggregating per-function execution times on the entire benchmark run.}
		\label{fig:functionSummary}
		\end{center}
	\end{figure}

	We can also see the impact of the \emph{parallelization overhead}: it is represented in its various forms as red blocks in the timeline, however the clearest way to quantify its cumulative impact on the performance is by using the \emph{Function summary} tool. As it can be seen in Fig.\ref{fig:functionSummary}, the overhead generated by OpenMP's loop management has a significant impact. On the other hand MPI\_Wait and OpenMP's barriers come much further down in the list, meaning that the impact of parallelization overhead in Lulesh is way greater than that caused by any load imbalance.
\end{enumerate}

\listoftodos[TODO List (to be removed in final version)]

\end{document}

%eof
